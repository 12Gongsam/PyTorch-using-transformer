{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyO+7cipEhj+B/J8Kq27xSGE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install Korpora konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":541},"id":"niyGp-ReKmfA","executionInfo":{"status":"ok","timestamp":1704802816188,"user_tz":-540,"elapsed":8224,"user":{"displayName":"JUNHA HWANG","userId":"15713937348463840886"}},"outputId":"e63b7fb9-b4f1-4ec7-9009-7f5410d5f70b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Korpora\n","  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m909.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses>=0.6 (from Korpora)\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (1.23.5)\n","Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (4.66.1)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.31.0)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.0.1)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2023.11.17)\n","Installing collected packages: dataclasses, JPype1, Korpora, konlpy\n","Successfully installed JPype1-1.5.0 Korpora-0.2.0 dataclasses-0.6 konlpy-0.6.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["# 합성곱 신경망"],"metadata":{"id":"vix_rSenJNia"}},{"cell_type":"code","source":["conv = torch.nn.Conv2d(\n","    in_channels,\n","    out_channels,\n","    kernel_size,\n","    stride=1,\n","    padding=0,\n","    dilation=1,\n","    groups=1,\n","    bias=True,\n","    padding_mode='zeros'\n",")"],"metadata":{"id":"rKJQNHBUVgNZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["합성곱 모델"],"metadata":{"id":"pZ3EWJ_GJPXg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaQMtiM3ilS1"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1\n","            ),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n","            ),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","\n","        self.fc = nn.Linear(32 * 32 * 32, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = torch.flatten(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"markdown","source":["## 합성곱 신경망으로 텍스트 분류"],"metadata":{"id":"AUAW_16HKP8m"}},{"cell_type":"code","source":["class SentenceClassifier(nn.Module):\n","    def __init__(self, pretrained_embedding, filter_sizes, max_length, dropout=0.5):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding.from_pretrained(\n","            torch.tensor(pretrained_embedding, dtype=torch.float32)\n","        )\n","        embedding_dim = self.embedding.weight.shape[1]\n","\n","        conv = []\n","        for size in filter_sizes:\n","            conv.append(\n","                nn.Sequential(\n","                    nn.Conv1d(\n","                        in_channels=embedding_dim,\n","                        out_channels=1,\n","                        kernel_size=size\n","                    ),\n","                    nn.ReLU(),\n","                    nn.MaxPool1d(kernel_size=max_length-size-1),\n","                )\n","            )\n","        self.conv_filters = nn.ModuleList(conv)\n","\n","        output_size = len(filter_sizes)\n","        self.pre_classifier = nn.Linear(output_size, output_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifier = nn.Linear(output_size, 1)\n","\n","    def forward(self, inputs):\n","        embeddings = self.embedding(inputs)\n","        embeddings = embeddings.permute(0, 2, 1)\n","\n","        conv_outputs = [conv(embeddings) for conv in self.conv_filters]\n","        concat_outputs = torch.cat([conv.squeeze(-1) for conv in conv_outputs], dim=1)\n","\n","        logits = self.pre_classifier(concat_outputs)\n","        logits = self.dropout(logits)\n","        logits = self.classifier(logits)\n","        return logits"],"metadata":{"id":"enjcGtSfJYAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from Korpora import Korpora\n","\n","\n","corpus = Korpora.load(\"nsmc\")\n","corpus_df = pd.DataFrame(corpus.test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MWH20zOKsiC","executionInfo":{"status":"ok","timestamp":1704802848279,"user_tz":-540,"elapsed":2234,"user":{"displayName":"JUNHA HWANG","userId":"15713937348463840886"}},"outputId":"5146463f-e733-4246-c0d2-7f4235c4ab68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n","    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n","\n","    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n","    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n","    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n","\n","    # Description\n","    Author : e9t@github\n","    Repository : https://github.com/e9t/nsmc\n","    References : www.lucypark.kr/docs/2015-pyconkr/#39\n","\n","    Naver sentiment movie corpus v1.0\n","    This is a movie review dataset in the Korean language.\n","    Reviews were scraped from Naver Movies.\n","\n","    The dataset construction is based on the method noted in\n","    [Large movie review dataset][^1] from Maas et al., 2011.\n","\n","    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n","\n","    # License\n","    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n","    Details in https://creativecommons.org/publicdomain/zero/1.0/\n","\n"]},{"output_type":"stream","name":"stderr","text":["[nsmc] download ratings_train.txt: 14.6MB [00:00, 91.9MB/s]                           \n","[nsmc] download ratings_test.txt: 4.90MB [00:00, 38.4MB/s]                            \n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","from konlpy.tag import Okt\n","\n","tokenizer = Okt()\n","tokens = [tokenizer.morphs(review) for review in corpus_df.text]\n","\n","word2vec = Word2Vec(\n","    sentences=tokens,\n","    vector_size=128,\n","    window=5,\n","    min_count=1,\n","    sg=1,\n","    epochs=3,\n","    max_final_vocab=10000\n",")"],"metadata":{"id":"UfZGgntuK0ak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = corpus_df.sample(frac=0.9, random_state=42)\n","test = corpus_df.drop(train.index)\n","\n","print(train.head(5).to_markdown())\n","print(\"Training Data Size :\", len(train))\n","print(\"Testing Data Size :\", len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyczGrHgLSHJ","executionInfo":{"status":"ok","timestamp":1704803081076,"user_tz":-540,"elapsed":319,"user":{"displayName":"JUNHA HWANG","userId":"15713937348463840886"}},"outputId":"b9f4c2ff-6ddc-444c-95a7-47683833778f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["|       | text                                                                                     |   label |\n","|------:|:-----------------------------------------------------------------------------------------|--------:|\n","| 33553 | 모든 편견을 날려 버리는 가슴 따뜻한 영화. 로버트 드 니로, 필립 세이모어 호프만 영원하라. |       1 |\n","|  9427 | 무한 리메이크의 소재. 감독의 역량은 항상 그 자리에...                                    |       0 |\n","|   199 | 신날 것 없는 애니.                                                                       |       0 |\n","| 12447 | 잔잔 격동                                                                                |       1 |\n","| 39489 | 오랜만에 찾은 주말의 명화의 보석                                                         |       1 |\n","Training Data Size : 45000\n","Testing Data Size : 5000\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","\n","def build_vocab(corpus, n_vocab, special_tokens):\n","    counter = Counter()\n","    for tokens in corpus:\n","        counter.update(tokens)\n","    vocab = special_tokens\n","    for token, count in counter.most_common(n_vocab):\n","        vocab.append(token)\n","    return vocab\n","\n","\n","tokenizer = Okt()\n","train_tokens = [tokenizer.morphs(review) for review in train.text]\n","test_tokens = [tokenizer.morphs(review) for review in test.text]\n","\n","vocab = build_vocab(corpus=train_tokens, n_vocab=5000, special_tokens=[\"<pad>\", \"<unk>\"])\n","token_to_id = {token: idx for idx, token in enumerate(vocab)}\n","id_to_token = {idx: token for idx, token in enumerate(vocab)}"],"metadata":{"id":"T_VEIt4ZLTCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def pad_sequences(sequences, max_length, pad_value):\n","    result = list()\n","    for sequence in sequences:\n","        sequence = sequence[:max_length]\n","        pad_length = max_length - len(sequence)\n","        padded_sequence = sequence + [pad_value] * pad_length\n","        result.append(padded_sequence)\n","    return np.asarray(result)\n","\n","\n","unk_id = token_to_id[\"<unk>\"]\n","train_ids = [\n","    [token_to_id.get(token, unk_id) for token in review] for review in train_tokens\n","]\n","test_ids = [\n","    [token_to_id.get(token, unk_id) for token in review] for review in test_tokens\n","]\n","\n","max_length = 32\n","pad_id = token_to_id[\"<pad>\"]\n","train_ids = pad_sequences(train_ids, max_length, pad_id)\n","test_ids = pad_sequences(test_ids, max_length, pad_id)"],"metadata":{"id":"qcu_icp6LaRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","train_ids = torch.tensor(train_ids)\n","test_ids = torch.tensor(test_ids)\n","\n","train_labels = torch.tensor(train.label.values, dtype=torch.float32)\n","test_labels = torch.tensor(test.label.values, dtype=torch.float32)\n","\n","train_dataset = TensorDataset(train_ids, train_labels)\n","test_dataset = TensorDataset(test_ids, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"metadata":{"id":"vqp-e1NYLcyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_vocab = len(token_to_id)\n","embedding_dim = 128\n","\n","\n","init_embeddings = np.zeros((n_vocab, embedding_dim))\n","\n","for index, token in id_to_token.items():\n","    if token not in [\"<pad>\", \"<unk>\"]:\n","        init_embeddings[index] = word2vec.wv[token]\n","\n","embedding_layer = nn.Embedding.from_pretrained(\n","    torch.tensor(init_embeddings, dtype=torch.float32)\n",")"],"metadata":{"id":"4ACF0NvyLkiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import optim\n","\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","filter_sizes = [3, 3, 4, 4, 5, 5]\n","classifier = SentenceClassifier(\n","    pretrained_embedding=init_embeddings,\n","    filter_sizes=filter_sizes,\n","    max_length=max_length\n",").to(device)\n","criterion = nn.BCEWithLogitsLoss().to(device)\n","optimizer = optim.RMSprop(classifier.parameters(), lr=0.001)"],"metadata":{"id":"aLqLb_1_NX_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, datasets, criterion, optimizer, device, interval):\n","    model.train()\n","    losses = list()\n","\n","    for step, (input_ids, labels) in enumerate(datasets):\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device).unsqueeze(1)\n","\n","        logits = model(input_ids)\n","        loss = criterion(logits, labels)\n","        losses.append(loss.item())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if step % interval == 0:\n","            print(f\"Train Loss {step} : {np.mean(losses)}\")\n","\n","\n","def test(model, datasets, criterion, device):\n","    model.eval()\n","    losses = list()\n","    corrects = list()\n","\n","    for step, (input_ids, labels) in enumerate(datasets):\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device).unsqueeze(1)\n","\n","        logits = model(input_ids)\n","        loss = criterion(logits, labels)\n","        losses.append(loss.item())\n","        yhat = torch.sigmoid(logits)>.5\n","        corrects.extend(\n","            torch.eq(yhat, labels).cpu().tolist()\n","        )\n","\n","    print(f\"Val Loss : {np.mean(losses)}, Val Accuracy : {np.mean(corrects)}\")\n","\n","\n","epochs = 5\n","interval = 500\n","\n","for epoch in range(epochs):\n","    train(classifier, train_loader, criterion, optimizer, device, interval)\n","    test(classifier, test_loader, criterion, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6o_MpCEdNSL5","executionInfo":{"status":"ok","timestamp":1704803602591,"user_tz":-540,"elapsed":63604,"user":{"displayName":"JUNHA HWANG","userId":"15713937348463840886"}},"outputId":"043b96b6-c41c-4e96-86fe-86631b39edea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Loss 0 : 0.6855735182762146\n","Train Loss 500 : 0.5711953860081123\n","Train Loss 1000 : 0.5395063562886222\n","Train Loss 1500 : 0.5275033957000417\n","Train Loss 2000 : 0.520028662057533\n","Train Loss 2500 : 0.5127629184606122\n","Val Loss : 0.46173308599299895, Val Accuracy : 0.7782\n","Train Loss 0 : 0.3967489004135132\n","Train Loss 500 : 0.48438875400972464\n","Train Loss 1000 : 0.48124899706997715\n","Train Loss 1500 : 0.47723254152411704\n","Train Loss 2000 : 0.47876962087769204\n","Train Loss 2500 : 0.4790652598537764\n","Val Loss : 0.46463947159985003, Val Accuracy : 0.775\n","Train Loss 0 : 0.4646646976470947\n","Train Loss 500 : 0.4668546715479887\n","Train Loss 1000 : 0.4673355486575183\n","Train Loss 1500 : 0.47336803037154523\n","Train Loss 2000 : 0.47278635903842925\n","Train Loss 2500 : 0.472806180902168\n","Val Loss : 0.44774493836937623, Val Accuracy : 0.7892\n","Train Loss 0 : 0.40346747636795044\n","Train Loss 500 : 0.47043911482164724\n","Train Loss 1000 : 0.46831013448350317\n","Train Loss 1500 : 0.4683362954978066\n","Train Loss 2000 : 0.46754064386722627\n","Train Loss 2500 : 0.4676177616967339\n","Val Loss : 0.4437521444722867, Val Accuracy : 0.7892\n","Train Loss 0 : 0.6699215769767761\n","Train Loss 500 : 0.45549909960842894\n","Train Loss 1000 : 0.4582036434115468\n","Train Loss 1500 : 0.45926565801517555\n","Train Loss 2000 : 0.4609711751125861\n","Train Loss 2500 : 0.46053939917739606\n","Val Loss : 0.4456457084598252, Val Accuracy : 0.7896\n"]}]}]}